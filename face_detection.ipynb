{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-pythonNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in c:\\users\\admin\\anaconda3\\lib\\site-packages (from opencv-python) (1.18.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return video from the first webcam on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importing the neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import smtplib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's return video from the first webcam on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenCV already contains many pre-trained classifiers for face, eyes, smile etc. Those XML files are stored in opencv/data/haarcascades/ folder\n",
    "- so lets load in the face and body pre-trained classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_fullbody.xml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add your email account credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_email = \"youremail@gmail.com\"\n",
    "password = \"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next, we need to declare all our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = False\n",
    "detection_stopped_time = None\n",
    "timer_started = False\n",
    "SECONDS_TO_RECORD_AFTER_DETECTION = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next, we get the frame size and then the frame character code which is like the format the video will be saved as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = (int(cap.get(3)), int(cap.get(4)))\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lets convert our frame into a greyscale image. all these classifiers requires a greyscale image to do the classification\n",
    "- it will tell us the presence and location of any image in the greyscale image\n",
    "- the gray variable, returns a list of positions of faces that exist such as the x,y, width and height\n",
    "- we then detect the faces and bodies in the gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.05, 4)\n",
    "    bodies = face_cascade.detectMultiScale(gray, 1.05, 4) \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- have we seen or detected any face or bodies? if yes, then we ask, are we currently recording?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- have we seen or detected any face or bodies? if yes, then we ask, are we currently recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    if len(faces) + len(bodies) > 0:\n",
    "        if detection:\n",
    "            timer_started = False\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- but if we were not recording before, then we need to since we have detected something.\n",
    "- get the current time\n",
    "- use that as our file name\n",
    "- start the video output string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "        else:\n",
    "            detection = True\n",
    "            current_time = datetime.datetime.now().strftime(\"%d-%m-%y-%H-%M-%S\")\n",
    "            out = cv2.VideoWriter(f\"{current_time}.mp4\", fourcc, 20, frame_size)\n",
    "            print(\"started recording\")\n",
    "            with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as connection:\n",
    "                connection.ehlo()\n",
    "                connection.login(user=my_email, password=password)\n",
    "                connection.sendmail(from_addr=my_email, to_addrs=my_email,\n",
    "                                    msg=f\"Subject: Movement tracker\\n\\n\"\n",
    "                                        f\"your movement tracker started at: {current_time}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- continuing, we go to the elif, if we have not detected anything and we are recording, then its time to start the timer and see if any faces or bodies come into the camera withing that time or duration we already set\n",
    "- if the timer has started we check to see if the timer has expired, \n",
    "- if it has, then we stop the recording\n",
    "- if it hasnt we just then continue\n",
    "\n",
    "if the timer has not started we start it and keep track of when the timer was started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif detection:\n",
    "        if timer_started:\n",
    "            if time.time() - detection_stopped_time >= SECONDS_TO_RECORD_AFTER_DETECTION:\n",
    "                detection = False\n",
    "                timer_started = False\n",
    "                out.release()\n",
    "                print(\"Stop recording!\")\n",
    "                with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as connection:\n",
    "                    connection.ehlo()\n",
    "                    connection.login(user=my_email, password=password)\n",
    "                    connection.sendmail(from_addr=my_email, to_addrs=my_email,\n",
    "                                        msg=f\"Subject: Movement tracker\\n\\n\"\n",
    "                                            f\"your movement tracker stopped at: {current_time}\")\n",
    "        else:\n",
    "            timer_started = True\n",
    "            detection_stopped_time = time.time()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "then we check if we are detecting something? if we are, then write\n",
    "then we show the current frame\n",
    "and press 'q' if you want to quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detection:\n",
    "        out.write(frame)\n",
    "    \n",
    "    cv2.imshow(\"camera\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finally, we release all our resources and destroy all open cv windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
